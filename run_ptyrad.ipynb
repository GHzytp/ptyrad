{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PtyRAD - PTYchographic Reconstruction with Automatic Differentiation\n",
    "\n",
    " Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2024.03.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tifffile import imread, imwrite\n",
    "\n",
    "GPUID = 0\n",
    "DEVICE = torch.device('cuda:' + str(GPUID))\n",
    "print('Execution device: ', DEVICE)\n",
    "print('PyTorch version: ', torch.__version__)\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "print('CUDA version: ', torch.version.cuda)\n",
    "print('CUDA device:', torch.cuda.get_device_name(GPUID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptyrad.initialization import Initializer\n",
    "from ptyrad.models import PtychoAD\n",
    "from ptyrad.optimization import CombinedLoss, CombinedConstraint, ptycho_recon, loss_logger\n",
    "from ptyrad.visualization import plot_forward_pass\n",
    "from ptyrad.utils import test_loss_fn, make_batches, make_save_dict, make_recon_params_dict, shuffle_batches, get_size_bytes, time_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Initialize optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ptyrad.demos.params_CNS import exp_params, source_params\n",
    "#from ptyrad.demos.params_PSO_128 import exp_params, source_params\n",
    "#from ptyrad.demos.params_PSO_256 import exp_params, source_params\n",
    "#from ptyrad.demos.params_tBL_WSe2 import exp_params, source_params\n",
    "from ptyrad.demos.params_BaM_128 import exp_params, source_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init = Initializer(exp_params, source_params).init_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(init.init_variables['crop_pos'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'init_variables': init.init_variables,\n",
    "    'lr_params':{\n",
    "        'obja': 5e-4,\n",
    "        'objp': 5e-4,\n",
    "        'probe': 5e-4, \n",
    "        'probe_pos_shifts': 0}}\n",
    "\n",
    "model = PtychoAD(model_params, device=DEVICE)\n",
    "\n",
    "# Use model.set_optimizer(new_lr_params) to update the variable flag and optimizer_params\n",
    "optimizer = torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this to edit learning rate if needed some refinement\n",
    "\n",
    "# model.set_optimizer(lr_params={'obja': 1e-4,\n",
    "#                                'objp': 1e-4,\n",
    "#                                'probe': 1e-4, \n",
    "#                                'probe_pos_shifts': 1e-4})\n",
    "# optimizer=torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,exp_params['N_scans'],2)\n",
    "dp_power = 0.5\n",
    "\n",
    "plot_forward_pass(model, indices, dp_power, init.init_variables['obj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the loss params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_params = {\n",
    "    'loss_single': {'state':  True,  'weight': 1.0, 'dp_pow': 0.5},\n",
    "    'loss_pacbed': {'state': False,  'weight': 1.0, 'dp_pow': 0.2},\n",
    "    'loss_tv'    : {'state': False,  'weight': 1e-5},\n",
    "    'loss_l1'    : {'state': False,   'weight': 0.1},\n",
    "    'loss_l2'    : {'state': False,  'weight': 1.0},\n",
    "    'loss_postiv': {'state':  False,  'weight': 1.0}\n",
    "}\n",
    "\n",
    "indices = np.random.randint(0,exp_params['N_scans'],64)\n",
    "loss_fn = CombinedLoss(loss_params, device=DEVICE)\n",
    "test_loss_fn(model, indices, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the iteration-wise constraint params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_params = {\n",
    "    'ortho_pmode'   : {'freq': 1},\n",
    "    'ortho_omode'   : {'freq': None},\n",
    "    'kz_filter'     : {'freq': 1, 'beta':1, 'alpha':1, 'z_pad':None},\n",
    "    'postiv'        : {'freq': 1},\n",
    "    'fix_probe_int' : {'freq': 1}\n",
    "}\n",
    "\n",
    "constraint_fn = CombinedConstraint(constraint_params, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Main optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NITER = 5\n",
    "BATCH_SIZE = 256\n",
    "GROUP = 'random' #'sparse'\n",
    "\n",
    "\n",
    "indices = np.arange(model.measurements.size(0))\n",
    "pos = model.crop_pos.cpu().numpy()\n",
    "batches = make_batches(indices, pos, BATCH_SIZE, group = GROUP)\n",
    "\n",
    "output_path = f\"output/BaM/{model.opt_objp.size(0)}obj_{model.opt_objp.size(1)}slice_N{len(indices)}_dp{model.measurements.size(1)}_lr{model_params['lr_params']['objp']:.0e}_b{BATCH_SIZE}_{GROUP}/\"\n",
    "print(f\"output_path = {output_path}\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "recon_params = make_recon_params_dict(NITER, BATCH_SIZE, GROUP, batches, output_path)\n",
    "\n",
    "loss_iters = []\n",
    "for iter in range(1, NITER+1):\n",
    "    \n",
    "    batches = shuffle_batches(batches, BATCH_SIZE, GROUP)\n",
    "    batch_losses, iter_t = ptycho_recon(batches, model, optimizer, loss_fn, constraint_fn, iter)\n",
    "    loss_iters.append((iter, loss_logger(batch_losses, iter, iter_t)))\n",
    "    \n",
    "    ## Saving\n",
    "    if iter % 5 == 0:\n",
    "        save_dict = make_save_dict(model, exp_params, source_params, loss_params, constraint_params, recon_params, loss_iters, iter_t, iter, batch_losses)\n",
    "        torch.save(save_dict, os.path.join(output_path, f\"model_iter{str(iter).zfill(4)}.pt\"))\n",
    "        imwrite(os.path.join(output_path, f\"objp_iter{str(iter).zfill(4)}.tif\"), model.opt_objp[0].detach().cpu().numpy().astype('float32'))\n",
    "        imwrite(os.path.join(output_path, f\"probe_amp_iter{str(iter).zfill(4)}.tif\"), model.opt_probe.reshape(-1, model.opt_probe.size(-1)).t().abs().detach().cpu().numpy().astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plot of the loss curve\n",
    "plt.figure()\n",
    "plt.plot(np.array(loss_iters)[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the initial probe intensity, CBED intensity, and optimized probe int\n",
    "init_probe_int = np.sum(np.abs(init.init_variables['probe'])**2)\n",
    "init_CBED_int = np.sum(np.mean(init.init_variables['measurements'], 0))\n",
    "opt_probe_int = model.opt_probe.abs().pow(2).sum().detach().cpu().numpy()\n",
    "print(f\"{init_probe_int}, {init_CBED_int}, {opt_probe_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the probe modes\n",
    "init_probe = init.init_variables['probe']\n",
    "opt_probe = model.opt_probe.detach().cpu().numpy()\n",
    "fig, axs = plt.subplots(2, len(opt_probe), figsize=(len(opt_probe)*2.5, 6))\n",
    "for i in range(len(opt_probe)):\n",
    "    ax_init = axs[0, i]\n",
    "    ax_init.set_title(f\"Init probe {i}\")\n",
    "    im_init = ax_init.imshow(np.abs(init_probe[i]))\n",
    "    ax_init.axis('off')\n",
    "    plt.colorbar(im_init, ax=ax_init, shrink=0.6)\n",
    "\n",
    "    ax_opt = axs[1, i]\n",
    "    ax_opt.set_title(f\"Opt probe {i}\")\n",
    "    im_opt = ax_opt.imshow(np.abs(opt_probe[i]))\n",
    "    ax_opt.axis('off')\n",
    "    plt.colorbar(im_opt, ax=ax_opt, shrink=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptyrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
