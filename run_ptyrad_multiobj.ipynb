{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PtyRAD - PTYchographic Reconstruction with Automatic Differentiation\n",
    "\n",
    " Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2024.03.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import load_fields_from_mat, read_matv7_3\n",
    "from preprocess import preprocess_ptycho_output_dict \n",
    "from utils import complex_object_interp3d, near_field_evolution\n",
    "import optimization\n",
    "import models\n",
    "import visualization\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imwrite, imread\n",
    "import torch\n",
    "\n",
    "GPUID = 0\n",
    "DEVICE = torch.device(\"cuda:\" + str(GPUID))\n",
    "print(\"Execution device: \", DEVICE)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(GPUID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data path\n",
    "ptycho_output_mat_path = \"output/abtem/20240328_multi_object/cbed_WSe2_and_Cu_fov_42p86_39p97_dp180/1/roi_1_Ndp_180/MLs_L1_p2_g256_dpFlip_T/Niter100.mat\" #\"data/CNS_from_Hari/Niter10000.mat\"\n",
    "#ptycho_output_mat_path = \"output/abtem/20240328_multi_object/cbed_WSe2_fov_42p86_39p97_dp180/1/roi_1_Ndp_180/MLs_L1_p2_g64_dpFlip_T/Niter100.mat\" #\"data/CNS_from_Hari/Niter10000.mat\"\n",
    "\n",
    "#exp_CBED_path =          \"data/CNS_from_Hari/240327_fov_23p044A_x_24p402A_thickness_9p978A_step0p28_conv30_dfm100_det70_TDS_2configs_xdirection_Co_0p25_Nb_0_S_0.mat\" \n",
    "exp_CBED_path =          \"output/abtem/20240328_multi_object/cbed_WSe2_and_Cu_fov_42p86_39p97_dp180.tif\"\n",
    "#exp_CBED_path =          \"output/abtem/20240328_multi_object/cbed_WSe2_fov_42p86_39p97_dp180.tif\"\n",
    "\n",
    "\n",
    "print(\"Loading ptycho output and input CBED\")\n",
    "ptycho_output_dict = load_fields_from_mat(ptycho_output_mat_path, 'All', squeeze_me=True, simplify_cells=True)\n",
    "input_CBED         = imread(exp_CBED_path) #read_matv7_3(exp_CBED_path, 'cbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the CBED orientation\n",
    "print(f\"input_CBED.shape = {input_CBED.shape}\") # The .mat reads (164,164,82,87), note the 87 corresponds to the object horizontal direction (noted as N_scan_y in Hari's notation)\n",
    "input_CBED_reshape = input_CBED.reshape(input_CBED.shape[0]*input_CBED.shape[1], input_CBED.shape[2], input_CBED.shape[3], order = 'C')\n",
    "print(f\"input_CBED.shape = {input_CBED_reshape.shape}\")\n",
    "input_CBED_reshape = input_CBED_reshape.transpose(0,1,2) # To swap ky into the 1st dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and setting up the data dimension\n",
    "print(\"Preprocessing ptycho output and experimental CBED\\n\")\n",
    "probe, object, exp_params = preprocess_ptycho_output_dict(ptycho_output_dict)\n",
    "cbeds                     = input_CBED_reshape # preprocess_CBED(exp_CBED) # (Nscan, ky, kx) that matches the .tif view\n",
    "\n",
    "# Prepare the experimental param for forward model and dataset generation\n",
    "lambd           = exp_params['lambd']\n",
    "dx_spec         = exp_params['dx_spec']\n",
    "z_distance      = 8 #exp_params['z_distance_arr'] # Ang, for 2D input, put the final desired total thickness if you're planning to do multislice\n",
    "probe_positions = exp_params['probe_positions']\n",
    "Nlayer          = exp_params['Nlayer']\n",
    "N_scans         = exp_params['N_scans']\n",
    "\n",
    "# Preprocessing variables for tBL-WSe2 with Themis\n",
    "object = object[None, :,:]#object.transpose((2,0,1)) # Converting object into (Nz, Ny, Nx)\n",
    "probe = probe.transpose((2,0,1))        # Converting probe into (pmode, Ny, Nx)\n",
    "      \n",
    "print(f\"\\nobject dtype/shape          (Nz, Ny, Nx) = {object.dtype}, {object.shape},\\\n",
    "        \\nprobe data dtype/shape   (pmode, Ny, Nx) = {probe.dtype}, {probe.shape},\\\n",
    "        \\ncbeds data dtype/shape       (N, Ky, Kx) = {cbeds.dtype}, {cbeds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the object, probe, probe position, propagator in np array\n",
    "\n",
    "# Reslice the z slices\n",
    "final_z = 8 # z slices #21 for PSO\n",
    "z_zoom = final_z / Nlayer\n",
    "z_distance_final = z_distance / z_zoom # Scale the interlayer distance based on z_zoom\n",
    "z_extent = final_z * z_distance_final\n",
    "object_interp = complex_object_interp3d(object, (z_zoom, 1, 1), z_axis = 0, use_np_or_cp = 'np') # Use cp for faster interpolation and convert it back to np with .get() as a default postprocessing\n",
    "print(f\"z_zoom = {z_zoom}, final_z = {final_z} slices, z_distance_final = {z_distance_final:.4f} Ang, z_extent = {z_extent:4f} Ang\")\n",
    "\n",
    "# Calculate the crop coordinates with floating points\n",
    "probe_positions_yx   = probe_positions[:, [1,0]] # The first index after shifting is the row index (along vertical axis)\n",
    "crop_coordinates     = probe_positions_yx + np.ceil((object_interp.shape[-1]/2) - (probe.shape[-1]/2)) - 1 # For Matlab - Python index shift\n",
    "sub_px_shift         = crop_coordinates - np.round(crop_coordinates) # This shift (tH, tW) would be added to the probe to compensate the integer obj cropping\n",
    "crop_indices         = np.round(crop_coordinates) # This one is rounded and \n",
    "\n",
    "## Calculate propagator for multislice forward model\n",
    "extent = dx_spec * np.array(probe.shape[-2:])\n",
    "_, H, _, _ = near_field_evolution(probe.shape[-2:], z_distance_final, lambd, extent, use_ASM_only=True, use_np_or_cp='np')\n",
    "\n",
    "# Specify forward model accuracy options\n",
    "N_max = 9494\n",
    "pmode_max = 2 # 2\n",
    "omode_max = 4 # 64 # By default we only do 1 object mode\n",
    "\n",
    "cbeds_data = cbeds[:N_max].astype('float32') \n",
    "cbeds_data = cbeds_data / (np.mean(cbeds_data, 0).max()) # Normalizing the cbeds_data so that the averaged CBED has max at 1. This will make each CBED has max somewhere ~ 1\n",
    "object_data = np.broadcast_to(object_interp, (omode_max, *object_interp.shape)) # Note that exact same object slice would get the same update, so this is not really a reasonable initialization except the shape\n",
    "probe_data = probe[:pmode_max, :, :].astype('complex64')\n",
    "probe_data = probe_data / (np.sum(np.abs(probe_data)**2)/np.sum(cbeds_data)*len(cbeds_data))**0.5 # Normalizing the probe_data so that the sum(|probe_data|**2) is the same with an averaged single CBED\n",
    "crop_indices_data = crop_indices[:N_max].astype('int16')\n",
    "shift_vec_data = sub_px_shift.astype('float32')\n",
    "\n",
    "H = H.astype('complex64')\n",
    "      \n",
    "print(f\"\\nobject_data dtype/shape (omode, Nz, Ny, Nx) = {object_data.dtype}, {object_data.shape}, \\\n",
    "        \\nprobe_data dtype/shape      (pmode, Ny, Nx) = {probe_data.dtype}, {probe_data.shape}, \\\n",
    "        \\ncrop_indices_data                     (N,2) = {crop_indices_data.dtype}, {crop_indices_data.shape}, \\\n",
    "        \\nshift_vec_data                        (N,2) = {shift_vec_data.dtype}, {shift_vec_data.shape}, \\\n",
    "        \\ncbeds_data dtype/shape          (N, Ky, Kx) = {cbeds_data.dtype}, {cbeds_data.shape}, \\\n",
    "        \\nH dtype/shape                      (Ky, Kx) = {H.dtype}, {H.shape}\")\n",
    "print(f\"\\nsum(|probe_data|**2) = {np.sum(np.abs(probe_data)**2):.02f}, while sum(cbeds_data)/len(cbeds_data) = {np.sum(cbeds_data)/len(cbeds_data):.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Everything is still np array (complex) from this cell, it'll be converted to tensor later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Initializing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any of the modules are modified, use this to reload\n",
    "reload(models)\n",
    "reload(optimization)\n",
    "reload(visualization)\n",
    "\n",
    "from models import PtychoAD\n",
    "from optimization import CombinedLoss\n",
    "from visualization import plot_forward_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import Fresnel_propagator\n",
    "\n",
    "# dfs = [-10,-9,-8,-7,-6,-5,-4,-3,-2,-1,0]\n",
    "# prop_probes = Fresnel_propagator(probe_data, dfs, lambd, extent)\n",
    "# print(f\"probe_data.shape = {probe_data.shape}, prop_probes.shape = {prop_probes.shape}\")\n",
    "# print(f\"sum(abs(probe)**2) = {np.sum(np.abs(probe_data)**2)}, \\nsum(abs(prop_probes)**2) = {np.sum(np.abs(prop_probes)**2, axis=(-3,-2,-1))}\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"probe int x-z\")\n",
    "# plt.imshow(np.abs(prop_probes[:,0,prop_probes.shape[-2]//2,:])**2, aspect=10)\n",
    "# plt.yticks(np.arange(0, prop_probes.shape[0]), dfs)\n",
    "# plt.ylabel('Ang along z')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tifffile import imread\n",
    "# #input_phase = imread(\"output/CNS_1obj_1slice_1e-3_2configs/objp_iter0050.tif\")[:,None]\n",
    "# input_phase = imread(\"output/CNS_32obj_initial_guess_32bit.tif\")[:,None]\n",
    "# input_phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obj              = np.exp(1j * 1e-8*np.random.rand(1,1,514,494)).astype('complex64')\n",
    "#init_obj              = np.exp(1j * 1e-8*np.random.rand(*object_data.shape)).astype('complex64')\n",
    "#init_obj               = np.exp(1j * np.concatenate([input_phase, 1e-8*np.random.rand(1,1,391,403)], axis=0)).astype('complex64') \n",
    "#init_obj              = object_data\n",
    "#init_obj               = np.exp(1j * input_phase).astype('complex64')\n",
    "#init_omode_occu       = [0.99, 0.01] #np.ones(len(init_obj))/len(init_obj)\n",
    "init_omode_occu       = np.ones(len(init_obj))/len(init_obj)\n",
    "init_probe            = probe_data\n",
    "init_crop_pos         = crop_indices_data\n",
    "init_probe_pos_shifts = shift_vec_data\n",
    "measurements  = torch.from_numpy(cbeds_data).to(DEVICE)\n",
    "\n",
    "model = PtychoAD(init_obj, init_omode_occu, init_probe, init_crop_pos, init_probe_pos_shifts, H, \n",
    "                lr_params={'obja': 0,\n",
    "                           'objp': 1e-3,\n",
    "                           'probe': 0, \n",
    "                           'probe_pos_shifts': 0},\n",
    "                device=DEVICE)\n",
    "\n",
    "# Use model.set_optimizer(new_lr_params) to update the variable flag and optimizer_params\n",
    "optimizer = torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.set_optimizer(lr_params={'obja': 0,\n",
    "#                                'objp': 5e-4,\n",
    "#                                'probe': 5e-4, \n",
    "#                                'probe_pos_shifts': 0})\n",
    "# optimizer=torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.01 Check the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,2,4,6]#np.random.randint(0,N_max,3)\n",
    "dp_power = 0.5\n",
    "\n",
    "plot_forward_pass(model, indices, dp_power, object_data, crop_indices_data, cbeds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Main optimization loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the loss params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_params = {\n",
    "    'loss_single': {'state':  True,  'weight': 1.0, 'dp_pow': 0.5},\n",
    "    'loss_pacbed': {'state': False,  'weight': 1.0, 'dp_pow': 0.2},\n",
    "    'loss_tv'    : {'state': False,  'weight': 1e-4},\n",
    "    'loss_l1'    : {'state': False,   'weight': 1e-2},\n",
    "    'loss_l2'    : {'state': False,  'weight': 1.0},\n",
    "    'loss_postiv': {'state':  True,  'weight': 1.0}\n",
    "}\n",
    "with torch.no_grad():\n",
    "    loss_fn = CombinedLoss(loss_params, device=DEVICE)\n",
    "    #np.random.seed(42)\n",
    "    indices = np.random.randint(0,N_max,32)\n",
    "    model_CBEDs, objp_patches = model(indices)\n",
    "    measured_CBEDs = measurements[indices]\n",
    "    loss_batch, losses = loss_fn(model_CBEDs, measured_CBEDs, objp_patches, model.omode_occu)\n",
    "\n",
    "# Print loss_name and loss_value with padding\n",
    "for loss_name, loss_value in zip(loss_params.keys(), losses):\n",
    "    print(f\"{loss_name.ljust(11)}: {loss_value.detach().cpu().numpy():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'output/multi_obj_WSe2_and_Cu_4obj_8slice_1e-3_dppow0.5_b64/'\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "NITER = 100\n",
    "BATCH_SIZE = 64\n",
    "num_batch = len(measurements) / BATCH_SIZE # The actual batch size would only be \"close\" if it's not divisible by len(measurments)\n",
    "cbed_shape = measurements.shape[1:]\n",
    "loss_iters = []\n",
    "\n",
    "for iter in range(NITER+1):\n",
    "    batch_losses = {name: [] for name in loss_params.keys()}\n",
    "    shuffled_indices = np.random.choice(len(measurements), size=len(measurements), replace=False) # Creates a shuffled 1D array of indices\n",
    "    batches = np.array_split(shuffled_indices, num_batch)                                         # return a list of `num_batch` arrays, or [batch0, batch1, ...]\n",
    "    start_iter_t = time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        torch.cuda.synchronize()\n",
    "        start_batch_t = time()\n",
    "        optimizer.zero_grad()\n",
    "        model_CBEDs, objp_patches = model(batch)\n",
    "        measured_CBEDs = measurements[batch]\n",
    "        loss_batch, losses = loss_fn(model_CBEDs, measured_CBEDs, objp_patches, model.omode_occu)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step() # batch update\n",
    "        torch.cuda.synchronize()\n",
    "        end_batch_t = time()\n",
    "\n",
    "        for loss_name, loss_value in zip(loss_params.keys(), losses):\n",
    "            batch_losses[loss_name].append(loss_value.detach().cpu().numpy())\n",
    "\n",
    "        if batch_idx in np.linspace(0, len(batches) - 1, num=6, dtype=int):\n",
    "            print(f\"Done batch {batch_idx} in iter {iter} in {(end_batch_t - start_batch_t):.3f} sec\")\n",
    "            \n",
    "    torch.cuda.synchronize()\n",
    "    end_iter_t = time()\n",
    "\n",
    "    avg_losses = {name: np.mean(values) for name, values in batch_losses.items()}\n",
    "    loss_str = ', '.join([f\"{name}: {value:.4f}\" for name, value in avg_losses.items()])\n",
    "    print(f\"Iter: {iter}, Total Loss: {sum(avg_losses.values()):.4f}, {loss_str}, \"\n",
    "          f\"in {(end_iter_t - start_iter_t) // 60} min {(end_iter_t - start_iter_t) % 60:03f} sec\")\n",
    "\n",
    "    loss_iters.append(sum(avg_losses.values()))      \n",
    "    \n",
    "    # # ## Saving\n",
    "    # if iter % 10 == 0:\n",
    "    #     torch.save(model.state_dict(), os.path.join(output_path, f\"model_iter{str(iter).zfill(4)}.pt\"))\n",
    "    #     imwrite(os.path.join(output_path, f\"objp_iter{str(iter).zfill(4)}_4D.tif\"), model.opt_objp.detach().cpu().numpy().astype('float32'))\n",
    "    #     imwrite(os.path.join(output_path, f\"objp_iter{str(iter).zfill(4)}_zsum.tif\"), model.opt_objp.sum(1).detach().cpu().numpy().astype('float32'))\n",
    "\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_z0.tif\"), model.opt_objp[:,0].detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_o1.tif\"), model.opt_objp[0].detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_omean.tif\"), model.opt_objp.mean(0).detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_ostd.tif\"), model.opt_objp.std(0).detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_zsum.tif\"), model.opt_objp.sum(1).detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_zsum_o1.tif\"), model.opt_objp.sum(1).detach().cpu().numpy()[0].astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_zsum_omean.tif\"), model.opt_objp.sum(1).mean(0).detach().cpu().numpy().astype('float32'))\n",
    "        # imwrite(os.path.join(output_path, f\"image_CNS_32obj_10slice_3e-4_random_postiv_iter{str(iter).zfill(4)}_zsum_ostd.tif\"), model.opt_objp.sum(1).std(0).detach().cpu().numpy().astype('float32'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,N_max,3)\n",
    "dp_power = 0.2\n",
    "\n",
    "plot_forward_pass(model, indices, dp_power, object_data, crop_indices_data, cbeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(8,8))\n",
    "im00=axs[0,0].imshow(model.opt_probe[0].abs().detach().cpu())\n",
    "im01=axs[0,1].imshow(np.abs(probe_data[0]))\n",
    "im10=axs[1,0].imshow(model.opt_probe[0].angle().detach().cpu())\n",
    "im11=axs[1,1].imshow(np.angle(probe_data[0]))\n",
    "\n",
    "axs[0,0].set_title(\"Model probe (amp)\")\n",
    "axs[0,1].set_title(\"Data probe (amp)\")\n",
    "axs[1,0].set_title(\"Model probe (phase)\")\n",
    "axs[1,1].set_title(\"Data probe (phase)\")\n",
    "\n",
    "\n",
    "fig.colorbar(im00)\n",
    "fig.colorbar(im01)\n",
    "fig.colorbar(im10)\n",
    "fig.colorbar(im11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot([x for x in loss_iters])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptyrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
