{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PtyRAD - PTYchographic Reconstruction with Automatic Differentiation\n",
    "\n",
    " Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2024.03.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major workflow\n",
    "- Rename \"`preprocess.py`\" into \"`initialization.py`\"\n",
    "- Make sure to keep things interact freely without too much coupling\n",
    "- Initialize class (takes user defined dict with flags and params), probably would do a numpy class and separate from PtyAD for clarity. Also I might be using the same initialize class for something else, like another reconstruction engine parallel to `Ptyrad`.\n",
    "\n",
    "```Exp:\n",
    "\n",
    "torch.save({'init_params':init_params,\n",
    "            'lr_params':lr_params,\n",
    "            'loss_params':loss_params,\n",
    "            'model_state_dict':model.state_dict()\n",
    "            }, PATH)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_io \n",
    "import initialization\n",
    "import models\n",
    "import forward\n",
    "import optimization\n",
    "import visualization\n",
    "import utils\n",
    "\n",
    "\n",
    "import os\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "GPUID = 0\n",
    "DEVICE = torch.device(\"cuda:\" + str(GPUID))\n",
    "print(\"Execution device: \", DEVICE)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(GPUID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any of the modules are modified, use this to reload\n",
    "reload(data_io)\n",
    "reload(initialization)\n",
    "reload(models)\n",
    "reload(forward)\n",
    "reload(optimization)\n",
    "reload(visualization)\n",
    "reload(utils)\n",
    "\n",
    "from initialization import Initializer, make_stem_probe, make_mixed_probe\n",
    "from models import PtychoAD\n",
    "from optimization import CombinedLoss, ptycho_recon, loss_logger\n",
    "from visualization import plot_forward_pass\n",
    "from utils import test_loss_fn, make_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Everything is still np array (complex) from this cell, it'll be converted to tensor later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Initialize optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptycho_output_mat_path = \"output/abtem/20240328_multi_object/cbed_WSe2_and_Cu_fov_42p86_39p97_dp180/1/roi_1_Ndp_180/MLs_L1_p2_g256_dpFlip_T/Niter100.mat\"\n",
    "# exp_CBED_path =          \"output/abtem/20240328_multi_object/cbed_WSe2_and_Cu_fov_42p86_39p97_dp180.tif\" \n",
    "\n",
    "# exp_params = {\n",
    "#     \"kv\": 200,\n",
    "#     \"alpha\":20,\n",
    "#     \"dx_spec\":0.1199,\n",
    "#     \"z_distance\":1,\n",
    "#     \"Nlayer\":1,\n",
    "#     \"N_scans\":9494,\n",
    "#     \"omode\":1,\n",
    "#     \"pmode\":1,\n",
    "#     \"probe_permute\": (2,0,1),\n",
    "#     \"cbeds_permute\":None,\n",
    "#     \"cbeds_reshape\": (9494,180,180)\n",
    "# }\n",
    "\n",
    "ptycho_output_mat_path = \"data/CNS_from_Hari/Niter10000.mat\"\n",
    "exp_CBED_path =          \"data/CNS_from_Hari/240327_fov_23p044A_x_24p402A_thickness_9p978A_step0p28_conv30_dfm100_det70_TDS_2configs_xdirection_Co_0p25_Nb_0_S_0.mat\" \n",
    "\n",
    "# Basic parameters\n",
    "voltage = 300 # kV\n",
    "conv_angle = 30 # mrad, semi-convergence angle\n",
    "Npix = 164 # Detector pixel number, EMPAD is 128. Only supports square detector for simplicity\n",
    "rbf = None  # Pixels of radius of BF disk, used to calculate dk\n",
    "dx_spec = 0.1406 # Ang\n",
    "df = -100 # Ang, positive defocus here refers to actual underfocus or weaker lens strength following Kirkland/abtem/ptychoshelves convention\n",
    "omode_max = 1\n",
    "pmode_max = 10\n",
    "pmode_init_pows = [0.02]\n",
    "\n",
    "exp_params = {\n",
    "    \"kv\": voltage,\n",
    "    \"conv_angle\":conv_angle,\n",
    "    \"Npix\":Npix,\n",
    "    \"rbf\": rbf,\n",
    "    \"dx_spec\":dx_spec,\n",
    "    \"defocus\": df,\n",
    "    \"z_distance\":1,\n",
    "    \"Nlayer\":1,\n",
    "    \"N_scans\":7134,\n",
    "    \"omode_max\":omode_max,\n",
    "    \"pmode_max\":pmode_max,\n",
    "    \"pmode_init_pows\": pmode_init_pows,\n",
    "    \"probe_permute\": None,#(2,0,1),\n",
    "    \"cbeds_permute\":(0,1,3,2),\n",
    "    \"cbeds_reshape\": (7134,164,164)\n",
    "}\n",
    "\n",
    "probe_simu_params = { ## Basic params\n",
    "                    \"kv\"             : exp_params['kv'],\n",
    "                    \"conv_angle\"     : exp_params['conv_angle'],\n",
    "                    \"Npix\"           : exp_params['Npix'],\n",
    "                    \"rbf\"            : exp_params['rbf'], # dk = conv_angle/1e3/rbf/wavelength\n",
    "                    \"dx\"             : exp_params['dx_spec'], # dx = 1/(dk*Npix) #angstrom\n",
    "                    \"print_info\"     : True,\n",
    "                    \"pmodes\"         : exp_params['pmode_max'],\n",
    "                    \"pmode_init_pows\": exp_params['pmode_init_pows'],\n",
    "                    ## Aberration coefficients\n",
    "                    \"df\": exp_params['defocus'], #first-order aberration (defocus) in angstrom, positive defocus here refers to actual underfocus or weaker lens strength following Kirkland's notation\n",
    "                    \"c3\":0, #third-order spherical aberration in angstrom\n",
    "                    \"c5\":0, #fifth-order spherical aberration in angstrom\n",
    "                    \"c7\":0, #seventh-order spherical aberration in angstrom\n",
    "                    \"f_a2\":0, #twofold astigmatism in angstrom\n",
    "                    \"f_a3\":0, #threefold astigmatism in angstrom\n",
    "                    \"f_c3\":0, #coma in angstrom\n",
    "                    \"theta_a2\":0, #azimuthal orientation in radian\n",
    "                    \"theta_a3\":0, #azimuthal orientation in radian\n",
    "                    \"theta_c3\":0, #azimuthal orientation in radian\n",
    "                    \"shifts\":[0,0], #shift probe center in angstrom\n",
    "                    }\n",
    "\n",
    "init_params = {\n",
    "    \"exp_params\"        :exp_params,\n",
    "    \"measurements\"      :{\"source\":\"mat\",       \"params\":[exp_CBED_path, 'cbed']},\n",
    "    \"obj\"               :{\"source\":\"simu\",      \"params\":(1,1,391,403)},\n",
    "#    \"obj\"               :{\"source\":\"mat\",      \"params\" :ptycho_output_mat_path},\n",
    "    \"probe\"             :{\"source\":\"simu\",      \"params\":probe_simu_params},\n",
    "#    \"probe\"             :{\"source\":\"mat\",      \"params\":ptycho_output_mat_path},\n",
    "    \"pos\"               :{\"source\":\"mat\",       \"params\":ptycho_output_mat_path},\n",
    "    \"omode_occu\"        :{\"source\":\"uniform\",   \"params\":None},\n",
    " }\n",
    "\n",
    "init = Initializer(init_params).init_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PtychoAD(init.init_variables, \n",
    "                lr_params={'obja': 0,\n",
    "                           'objp': 1e-3,\n",
    "                           'probe': 1e-3, \n",
    "                           'probe_pos_shifts': 0},\n",
    "                device=DEVICE)\n",
    "\n",
    "# Use model.set_optimizer(new_lr_params) to update the variable flag and optimizer_params\n",
    "optimizer = torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this to edit learning rate if needed some refinement\n",
    "\n",
    "# model.set_optimizer(lr_params={'obja': 0,\n",
    "#                                'objp': 1e-3,\n",
    "#                                'probe': 1e-3, \n",
    "#                                'probe_pos_shifts': 0})\n",
    "# optimizer=torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,exp_params['N_scans'],1)\n",
    "dp_power = 0.5\n",
    "\n",
    "plot_forward_pass(model, indices, dp_power, init.init_variables['obj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the loss params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_params = {\n",
    "    'loss_single': {'state':  True,  'weight': 1.0, 'dp_pow': 0.5},\n",
    "    'loss_pacbed': {'state': False,  'weight': 1.0, 'dp_pow': 0.2},\n",
    "    'loss_tv'    : {'state': False,  'weight': 1e-4},\n",
    "    'loss_l1'    : {'state': False,   'weight': 1e-2},\n",
    "    'loss_l2'    : {'state': False,  'weight': 1.0},\n",
    "    'loss_postiv': {'state':  True,  'weight': 1.0}\n",
    "}\n",
    "\n",
    "indices = np.random.randint(0,exp_params['N_scans'],256)\n",
    "loss_fn = CombinedLoss(loss_params, device=DEVICE)\n",
    "test_loss_fn(model, indices, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Main optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NITER = 10\n",
    "BATCH_SIZE = 256\n",
    "N_scans = exp_params['N_scans']\n",
    "num_batch = N_scans / BATCH_SIZE # The actual batch size would only be \"close\" if it's not divisible by len(measurments)\n",
    "cbed_shape = model.measurements.shape[1:]\n",
    "loss_iters = []\n",
    "\n",
    "# output_path = 'output/multi_obj_WSe2_and_Cu_4obj_8slice_1e-3_dppow0.5_b64/'\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for iter in range(NITER+1):\n",
    "    batches = make_batches(N_scans, num_batch)\n",
    "    batch_losses, iter_t = ptycho_recon(batches, model, optimizer, loss_fn)\n",
    "    loss_iters.append(loss_logger(batch_losses, iter, iter_t))\n",
    "    \n",
    "    # # ## Saving\n",
    "    # if iter % 10 == 0:\n",
    "    #     torch.save(model.state_dict(), os.path.join(output_path, f\"model_iter{str(iter).zfill(4)}.pt\"))\n",
    "    #     imwrite(os.path.join(output_path, f\"objp_iter{str(iter).zfill(4)}_4D.tif\"), model.opt_objp.detach().cpu().numpy().astype('float32'))\n",
    "    #     imwrite(os.path.join(output_path, f\"objp_iter{str(iter).zfill(4)}_zsum.tif\"), model.opt_objp.sum(1).detach().cpu().numpy().astype('float32'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptyrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
