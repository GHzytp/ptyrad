{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PtyRAD - PTYchographic Reconstruction with Automatic Differentiation\n",
    "\n",
    " Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2024.03.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worklog\n",
    "- 20240308: Start working on this\n",
    "- 20240310: Got it working as a close loop for single object with mixed probe\n",
    "- 20240311: Implemented mixed object and unified dimension for 2D and 3D\n",
    "- 20240313: Tried position correction, need to do it with real-valued object. Switch to 2 channels for probe and object.\n",
    "- 20240314: Got probe position correction roughly implemented with STN on object. Implemented obj phase L1, obj phase positivity, obj phase TV.\n",
    "- 20240315: Implemented forward model with batch, but turns out it's bottlenecking at the get_obj_ROI.\n",
    "- 20240316: Decided to roll back to integer get_obj_ROI.Implementd get_probes with torchvision.transformation.affine as well. Now everything is batch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Note\n",
    "\n",
    "## Done feature\n",
    "- Probe mode optimization (pmode, Ny, Nx)\n",
    "- Multi-object with 2/3D optimization (omode, Nz, Ny, Nx, 2)\n",
    "- Probe position correction with STN (roll back to integer obj position)\n",
    "- Obj phase L1, obj phase positivity, obj phase TV\n",
    "- Probe position corrcetion with v2.affine with shifted probe\n",
    "\n",
    "\n",
    "\n",
    "## TODO\n",
    "\n",
    "### Notebook\n",
    "- Loading steps\n",
    "- Preprocessing steps\n",
    "\n",
    "\n",
    "### Optimization\n",
    "- Batch calculation of forward model without breaking the backprop\n",
    "- Test regularization / constraint / multiscale consistence loss\n",
    "- Multiscale pyramidal reconstruction\n",
    "- Specify MLs / MLc\n",
    "\n",
    "### Initialization\n",
    "- Add loading initial guess\n",
    "- Add object and probe initialization (probe modes and object modes)\n",
    "\n",
    "### Input / Output\n",
    "- Add saving intermediate results\n",
    "- Add checkpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_CBED, preprocess_ptycho_output_dict \n",
    "from optimization import cbed_rmse\n",
    "from forward_model import multislice_forward_model_batch_all\n",
    "from utils import cplx_from_np, complex_object_interp3d, near_field_evolution\n",
    "from data_io import load_fields_from_mat, load_hdf5\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "#from visualization import plot_recon_progress\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "GPUID = 0\n",
    "DEVICE = torch.device(\"cuda:\" + str(GPUID))\n",
    "print(\"Execution device: \", DEVICE)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(GPUID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data path\n",
    "#ptycho_output_mat_path = \"data/data3D_300kV_df_20nm_alpha_21.4mrad_Cs_0.0um_dp_128_blur_0px_dose_1.0e+08ePerAng2/1/roi_1_Ndp_128/MLs_L1_p4_g32_Ns21_dz10_reg1_dec0.92_dpFlip_T/Niter500.mat\"\n",
    "#exp_CBED_path = \"data/data3D_300kV_df_20nm_alpha_21.4mrad_Cs_0.0um_dp_128_blur_0px_dose_1.0e+08ePerAng2/1/data_roi_1_Ndp_128_dp.hdf5\"\n",
    "\n",
    "# Exp PSO\n",
    "# ptycho_output_mat_path = \"data/MLs_L1_p8_g192_Ndp128_pc50_noModel_vp1_Ns21_dz10_reg1/Niter200.mat\"\n",
    "# exp_CBED_path = \"data/MLs_L1_p8_g192_Ndp128_pc50_noModel_vp1_Ns21_dz10_reg1/PSO_data_roi0_Ndp256_dp.hdf5\"\n",
    "\n",
    "# Exp PSO\n",
    "# ptycho_output_mat_path = \"data/MLs_L1_p4_g32_Ns21_dz10_dpFlip_T/Niter50_ML.mat\"\n",
    "# exp_CBED_path = \"data/MLs_L1_p4_g32_Ns21_dz10_dpFlip_T/data_roi_1_Ndp_128_dp.hdf5\"\n",
    "\n",
    "ptycho_output_mat_path = \"data/Fig_1h_24.9mrad_Themis/1/roi1_Ndp128_step128\\MLs_L1_p10_g128_pc0_noModel_updW100_mm_dpFlip_ud_T/Niter9000_v7.mat\"\n",
    "exp_CBED_path =          \"data/Fig_1h_24.9mrad_Themis/1/data_roi1_Ndp128_step128_dp.hdf5\"\n",
    "\n",
    "print(\"Loading ptycho output and input CBED\")\n",
    "ptycho_output_dict = load_fields_from_mat(ptycho_output_mat_path, 'All', squeeze_me=True, simplify_cells=True)\n",
    "#exp_CBED = load_empad_as_4D(exp_CBED_path, 128,130,128,128,'C')\n",
    "input_CBED, CBED_source = load_hdf5(exp_CBED_path, dataset_key='dp') \n",
    "# Note that loading Matlab-generated F-order HDF5 (kx, ky, Nscan) into Python would automatically make it C-order (Nscan, ky, kx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and setting up the data dimension\n",
    "\n",
    "print(\"Preprocessing ptycho output and experimental CBED\\n\")\n",
    "probe, object, exp_params = preprocess_ptycho_output_dict(ptycho_output_dict)\n",
    "cbeds                     = np.flip(input_CBED, axis=1) # preprocess_CBED(exp_CBED) # (Nscan, ky, kx) that matches the .tif view\n",
    "cbeds[cbeds<0] = 0\n",
    "\n",
    "# Prepare the experimental param for forward model and dataset generation\n",
    "lambd           = exp_params['lambd']\n",
    "dx_spec         = exp_params['dx_spec']\n",
    "z_distance      = 8 #exp_params['z_distance_arr'][0] # Ang, for 2D input, put the final desired total thickness if you're planning to do multislice\n",
    "probe_positions = exp_params['probe_positions']\n",
    "Nlayer          = exp_params['Nlayer']\n",
    "N_scans         = exp_params['N_scans']\n",
    "\n",
    "# Preprocessing variables for tBL-WSe2 with Themis\n",
    "object = object[None, :,:]#object.transpose((2,0,1)) # Converting object into (Nz, Ny, Nx)\n",
    "probe = probe.transpose((2,0,1))        # Converting probe into (pmode, Ny, Nx)\n",
    "      \n",
    "print(f\"\\nobject dtype/shape          (Nz, Ny, Nx) = {object.dtype}, {object.shape},\\\n",
    "        \\nprobe data dtype/shape   (pmode, Ny, Nx) = {probe.dtype}, {probe.shape},\\\n",
    "        \\ncbeds data dtype/shape       (N, Ky, Kx) = {cbeds.dtype}, {cbeds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reslice the z slices\n",
    "final_z = 8 # z slices #21 for PSO\n",
    "z_zoom = final_z / Nlayer\n",
    "z_distance = z_distance / z_zoom # Scale the interlayer distance based on z_zoom\n",
    "object = complex_object_interp3d(object, (z_zoom, 1, 1), z_axis = 0, use_np_or_cp = 'np') # Use cp for faster interpolation and convert it back to np with .get() as a default postprocessing\n",
    "\n",
    "# Calculate the crop coordinates with floating points\n",
    "probe_positions = probe_positions[:, [1,0]] # The first index after shifting is the row index (along vertical axis)\n",
    "crop_coordinates = probe_positions + np.ceil((object.shape[-1]/2) - (probe.shape[-1]/2)) - 1 # For Matlab - Python index shift\n",
    "sub_px_shift = crop_coordinates - np.round(crop_coordinates) # This shift (tH, tW) would be added to the probe to compensate the integer obj cropping\n",
    "crop_indices = np.round(crop_coordinates) # This one is rounded and \n",
    "\n",
    "## Calculate propagator for multislice forward model\n",
    "extent = dx_spec * np.array(probe.shape[-2:])\n",
    "_, H, _, _ = near_field_evolution(probe.shape[-2:], z_distance, lambd, extent, use_ASM_only=True, use_np_or_cp='np')\n",
    "\n",
    "# Specify forward model accuracy options\n",
    "N_max = 16384\n",
    "pmode_max = 10 # 4\n",
    "omode_max = 1 # By default we only do 1 object mode\n",
    "\n",
    "# Initialize probe / object if needed (expand them to desired dimension)\n",
    "if object.ndim == 2:\n",
    "      # (Ny, Nx) for 2D ptychography\n",
    "      object_data = object[None, :, :]\n",
    "      print(f\"Expanding 2D object (Ny, Nx) from {object.shape} to 3D object (Nz, Ny, Nx) {object_data.shape}\")\n",
    "elif object.ndim == 3:\n",
    "      # (Nz, Ny, Nx) for multislice (3D) ptycho\n",
    "      object_data = object\n",
    "      print(f\"Object is already 3D (Nz, Ny, Nx) with {object_data.shape}\")\n",
    "\n",
    "obj_power_factor = np.exp(np.log(0.02)/2/final_z) # Multiply the object by this factor would result a 2% total scattering intensity in the CBED after all the loss from all multiplicative slices\n",
    "\n",
    "object_data = np.stack([object_data if i < 1 else gaussian_filter(object_data, sigma = (0,i//2, i%2)) * obj_power_factor for i in range(omode_max)], axis=0).astype('complex64') # Adding gaussian blur to the obj modes\n",
    "probe_data = probe[:pmode_max, :, :].astype('complex64')\n",
    "crop_indices_data = crop_indices[:N_max].astype('int32')\n",
    "shift_vec_data = sub_px_shift.astype('float32')\n",
    "cbeds_data = cbeds[:N_max].astype('float32')\n",
    "H = H.astype('complex64')\n",
    "      \n",
    "print(f\"\\nobject_data dtype/shape (omode, Nz, Ny, Nx) = {object_data.dtype}, {object_data.shape}, \\\n",
    "        \\nprobe_data dtype/shape      (pmode, Ny, Nx) = {probe_data.dtype}, {probe_data.shape}, \\\n",
    "        \\ncrop_indices_data                     (N,2) = {crop_indices_data.dtype}, {crop_indices_data.shape}, \\\n",
    "        \\nshift_vec_data                        (N,2) = {shift_vec_data.dtype}, {shift_vec_data.shape}, \\\n",
    "        \\ncbeds_data dtype/shape          (N, Ky, Kx) = {cbeds_data.dtype}, {cbeds_data.shape}, \\\n",
    "        \\nH dtype/shape                      (Ky, Kx) = {H.dtype}, {H.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_px_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_indices_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Everything is still np array (complex) from this cell, it'll be converted to tensor later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently putting the model in the notbeook, but eventually would move to another module\n",
    "\n",
    "class PtychoAD(torch.nn.Module):\n",
    "    def __init__(self, init_obj, init_probe, init_crop_pos, init_probe_pos_shifts, H, lr_params=None, device='cuda:0'):\n",
    "        super(PtychoAD, self).__init__()\n",
    "        with torch.no_grad():\n",
    "            self.device = device\n",
    "            self.opt_obj = cplx_from_np(init_obj, cplx_type=\"amp_phase\", ndim=-1).to(self.device)\n",
    "            self.opt_probe = cplx_from_np(init_probe, cplx_type=\"amp_phase\", ndim=-1).to(self.device) \n",
    "            self.opt_probe_pos_shifts = torch.tensor(init_probe_pos_shifts, device=self.device)\n",
    "            self.crop_pos = torch.tensor(init_crop_pos, dtype=torch.int32, device=self.device)\n",
    "            self.H = torch.tensor(H, dtype=torch.complex64, device=self.device)\n",
    "            self.roi_shape = init_probe.shape[-2:]\n",
    "            self.shift_probes = (lr_params['probe_pos_shifts'] != 0) # Set shift_probes to False if lr_params['probe_pos_shifts'] = 0\n",
    "            \n",
    "            # Create a dictionary to store the optimizable tensors\n",
    "            self.optimizable_tensors = {\n",
    "                'obj': self.opt_obj,\n",
    "                'probe': self.opt_probe,\n",
    "                'probe_pos_shifts': self.opt_probe_pos_shifts\n",
    "            }\n",
    "\n",
    "            self.optimizer_params = []\n",
    "            if lr_params:\n",
    "                for param_name, lr in lr_params.items():\n",
    "                    if param_name in self.optimizable_tensors:\n",
    "                        self.optimizable_tensors[param_name].requires_grad = (lr != 0)  # Set requires_grad based on learning rate\n",
    "                        if lr != 0:\n",
    "                            self.optimizer_params.append({'params': [self.optimizable_tensors[param_name]], 'lr': lr})\n",
    "                    else:\n",
    "                        print(f\"Warning: '{param_name}' is not a valid parameter name.\")\n",
    "\n",
    "            print('PtychoAD major variables:')\n",
    "            for name, tensor in self.optimizable_tensors.items():\n",
    "                print(f\"{name}: {tensor.shape}, {tensor.dtype}, device:{tensor.device}, grad:{tensor.requires_grad}, lr:{lr_params[name]:.0e}\")\n",
    "            \n",
    "    def get_obj_ROI(self, indices):\n",
    "        \"\"\" Get object ROI with integer coordinates \"\"\"\n",
    "        # It's strongly recommended to do integer version of get_obj_ROI\n",
    "        # opt_obj.shape = (B,D,H,W,C) = (omode,D,H,W,2)\n",
    "        # object_patches = (N,B,D,H,W,2), N is the additional sample index within the input batch, B is now used for omode.\n",
    "        \n",
    "        height, width  = self.roi_shape[0], self.roi_shape[1]\n",
    "        object_patches = torch.zeros((len(indices), *self.opt_obj.shape[:2], height, width, 2)).to(self.device)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            height_start, height_end = self.crop_pos[idx,0], self.crop_pos[idx,0] + height\n",
    "            width_start,  width_end  = self.crop_pos[idx,1], self.crop_pos[idx,1] + width\n",
    "            object_patch      =  self.opt_obj[:, :, height_start:height_end, width_start:width_end, :] # object_patch (omode, D,H,W,2), 2 for the amp/phase channel\n",
    "            object_patches[i] = object_patch\n",
    "\n",
    "        return object_patches\n",
    "\n",
    "    def get_probes(self, indices):\n",
    "        \"\"\" Get probes for each position \"\"\"\n",
    "        # If you're not trying to optimize probe positions, there's not much point using sub-px shifted stationary probes\n",
    "        # This function will return a single probe when self.shift_probes = False,\n",
    "        # and would only be returning multiple sub-px shifted probes if you're optimizing self.opt_probe_pos_shifts\n",
    "\n",
    "        if self.shift_probes:\n",
    "            temp_probe = self.opt_probe.permute(0,3,1,2) # (pmode, Ny, Nx, 2) -> (pmode, 2, Ny, Nx)\n",
    "            probes = torch.zeros((len(indices), *temp_probe.shape)).to(self.device) # (N, pmode, 2, Ny, Nx)\n",
    "\n",
    "            for i, idx in enumerate(indices):\n",
    "                tH = self.opt_probe_pos_shifts[idx][0] # Note that translate (a,b) is in unit of px, although the doc says it's fractional\n",
    "                tW = self.opt_probe_pos_shifts[idx][1] # positive is moving to right/down for tW and tH.\n",
    "                probes[i] = v2.functional.affine(temp_probe, translate = (tW, tH), interpolation=v2.InterpolationMode.BILINEAR, angle=0, scale=1, shear=0) \n",
    "            probes = probes.permute(0,1,3,4,2) # (N, pmode, Ny, Nx, 2)\n",
    "        else:\n",
    "            probes = self.opt_probe[None,...] # Extend a singleton N dimension, essentially using same probe for all samples\n",
    "        \n",
    "        return probes\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        \"\"\" Doing the forward pass and get an output diffraction pattern for each input index \"\"\"\n",
    "        # The indices are passed as an array and representing the whole batch\n",
    "        \n",
    "        object_patches = self.get_obj_ROI(indices)\n",
    "        probes = self.get_probes(indices)\n",
    "        dp_fwd = multislice_forward_model_batch_all(object_patches, probes, self.H)\n",
    "        \n",
    "        return dp_fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create optimization object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_obj      = np.exp(1j * 0.05*np.random.rand(*object_data.shape)).astype('complex64') # init_obj = object_data\n",
    "init_obj              = object_data\n",
    "init_probe            = probe_data\n",
    "init_crop_pos         = crop_indices_data\n",
    "init_probe_pos_shifts = shift_vec_data\n",
    "measurements  = torch.from_numpy(cbeds_data).cuda()\n",
    "\n",
    "model = PtychoAD(init_obj, init_probe, init_crop_pos, init_probe_pos_shifts, H, \n",
    "                lr_params={'obj': 1e-3, \n",
    "                           'probe': 0, \n",
    "                           'probe_pos_shifts': 0},\n",
    "                device=DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [10000,100,200,300]\n",
    "dp_power = 0.5\n",
    "\n",
    "dp_fwd = model(indices).detach().cpu()\n",
    "obj_ROI = model.get_obj_ROI(indices).detach().cpu()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "    object_patch = np.angle(object_data[0,0,crop_indices_data[idx,0]:crop_indices_data[idx,0]+probe.shape[-1],crop_indices_data[idx,1]:crop_indices_data[idx,1]+probe.shape[-1]])\n",
    "    \n",
    "    axs[0, 0].imshow(obj_ROI[i,0,:,:,:,1].sum(0))\n",
    "    axs[0, 0].set_title(f\"Model obj {idx}\")\n",
    "\n",
    "    axs[0, 1].imshow(object_patch)\n",
    "    axs[0, 1].set_title(f\"Data obj {idx}\")\n",
    "\n",
    "    axs[1, 0].imshow(dp_fwd[i]**dp_power)\n",
    "    axs[1, 0].set_title(f\"Model CBED {idx}\")\n",
    "\n",
    "    axs[1, 1].imshow(cbeds_data[idx]**dp_power)\n",
    "    axs[1, 1].set_title(f\"Data CBED {idx}\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 128 # The actual batch size would only be \"close\" if it's not divisible by len(measurments)\n",
    "# num_batch = len(measurements)/BATCH_SIZE\n",
    "# shuffled_indices = np.random.choice(len(measurements), size = len(measurements), replace=False) # Creates a shuffled 1D array of indices\n",
    "# batches = np.array_split(shuffled_indices, num_batch) # return a list of `num_batch` arrays, or [batch0, batch1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.synchronize()\n",
    "# with torch.no_grad():\n",
    "#     for batch in batches:\n",
    "#         dp_fwd = model.get_obj_ROI(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "from torchmetrics.image import TotalVariation\n",
    "# https://lightning.ai/docs/torchmetrics/stable/image/total_variation.html \n",
    "# This TV only applies to the last 2 dim (N,C,H,W)\n",
    "\n",
    "NITER = 100\n",
    "BATCH_SIZE = 256 # The actual batch size would only be \"close\" if it's not divisible by len(measurments)\n",
    "num_batch = len(measurements)/BATCH_SIZE\n",
    "cbed_shape = measurements.shape[1:]\n",
    "loss_iters = []\n",
    "\n",
    "Softplus = torch.nn.Softplus(beta=100, threshold=2)\n",
    "tv = TotalVariation().to(DEVICE)\n",
    "for iter in range(NITER):\n",
    "    loss_batches = []\n",
    "    shuffled_indices = np.random.choice(len(measurements), size = len(measurements), replace=False) # Creates a shuffled 1D array of indices\n",
    "    batches = np.array_split(shuffled_indices, num_batch) # return a list of `num_batch` arrays, or [batch0, batch1, ...]\n",
    "\n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        start_batch_t = time()\n",
    "        \n",
    "        model_CBEDs = model(batch)\n",
    "        measured_CBEDs = measurements[batch]\n",
    "        \n",
    "        loss_single     = cbed_rmse(model_CBEDs.sqrt(), measured_CBEDs.sqrt())    \n",
    "        loss_pacbed     = 0 #cbed_rmse(model_CBEDs.mean(0).pow(0.2), measured_CBEDs.mean(0).pow(0.2)) # Ensuring the Position-averaged CBED are consistent as well\n",
    "        loss_tv         = 0 #1e-7 * tv(model.opt_obj[:,1])\n",
    "        loss_l1         = 0 #torch.mean(model.opt_obj[:,1].abs())\n",
    "        loss_batch      = loss_single + loss_pacbed + loss_tv + loss_l1\n",
    "        \n",
    "        loss_batch.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        end_batch_t = time()\n",
    "\n",
    "        # #Update the plots after each update\n",
    "        # AD_image = np.angle(model.opt_obj.detach().cpu()).sum(1)\n",
    "        # Input_image = np.angle(object_data).sum(axis=1)[0]\n",
    "\n",
    "        # # Show the figure per batch\n",
    "        # clear_output(wait=True)   \n",
    "        # fig = plot_recon_progress(iter, batch_idx, AD_image, Input_image)\n",
    "        # plt.show()\n",
    "        \n",
    "        loss_batches.append(loss_batch)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Done batch {batch_idx} in iter {iter} in {(end_batch_t - start_batch_t):.1f} sec\")\n",
    "    print(f\"Iter: {iter}, Loss_batch: {loss_batch:.3f}, Loss_single: {loss_single:.3f}, Loss_pacbed: {loss_pacbed:.3f}, Loss_tv: {loss_tv:.3f}, Loss_L1: {loss_l1:.3f}\")\n",
    "\n",
    "    # # Do a softplus constraint at the end of each iter without grad\n",
    "    # with torch.no_grad():\n",
    "    #     print(f\"Applying softplus to obj phase for positivity after iter {iter}\")\n",
    "    #     model.opt_obj[:,1] = Softplus(model.opt_obj[:,1])\n",
    "        \n",
    "    loss_iters.append(sum(loss_batches)/len(loss_batches))\n",
    "    print('Iter: {} Loss: {} '.format(iter, loss_iters[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(model.opt_obj.detach().cpu()[0,:,:,:,1].sum(0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imwrite\n",
    "imwrite(\"output/AD_image_WSe2_test8.tif\", model.opt_obj.detach().cpu().numpy()[0,...,1].astype('float32'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptyrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
