#!/bin/bash
#SBATCH --job-name=ptyrad
#SBATCH --mail-user=cl2696@cornell.edu       # Where to send mail
#SBATCH --nodes=1                            # number of nodes requested
#SBATCH --ntasks=1                           # number of tasks to run in parallel
#SBATCH --cpus-per-task=32                    # number of CPUs required for each task
#SBATCH --gres=gpu:a100:1                 # request a GPU #gpu:a100:1, gpu:2g.20gb:1
#SBATCH --time=00:10:00                      # Time limit hrs:min:sec
#SBATCH --output=logs/log_job_%j_ptyrad_tBL_WSe2.txt  # Standard output and error log to /logs, you need to create this folder first!

pwd; hostname; date

module load cuda/11.8

source activate ptyrad_acc

# Set the params_path variable
PARAMS_PATH="params/demo/tBL_WSe2_reconstruct.yml"
echo params_path = ${PARAMS_PATH}

python -u ./scripts/run_ptyrad.py --params_path "${PARAMS_PATH}" 2>&1 # This runs typical python on 1 GPU
# accelerate launch --multi_gpu --num_processes=2 --mixed_precision='no' ./scripts/run_ptyrad.py --params_path "${PARAMS_PATH}" 2>&1 # This runs DDP on 2 GPUs via `accelerate`
# accelerate launch --num_processes=1 --mixed_precision='fp16' ./scripts/run_ptyrad.py --params_path "${PARAMS_PATH}" 2>&1 # This runs DDP on 2 GPUs via `accelerate`

date