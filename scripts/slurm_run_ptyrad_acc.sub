#!/bin/bash
#SBATCH --job-name=multiGPU
#SBATCH --mail-user=cl2696@cornell.edu       # Where to send mail
#SBATCH --nodes=1                            # number of nodes requested
#SBATCH --ntasks=1                           # number of tasks to run in parallel
#SBATCH --cpus-per-task=32                    # number of CPUs required for each task
#SBATCH --gres=gpu:a100:2                 # request a GPU #gpu:a100:1, gpu:2g.20gb:1
#SBATCH --time=00:10:00                      # Time limit hrs:min:sec
#SBATCH --output=logs/log_job_%j_ptyrad_benchmark_acc2.txt  # Standard output and error log to /logs, you need to create this folder first!

pwd; hostname; date

module load cuda/11.8

source activate ptyrad_acc

# Set the params_path variable
PARAMS_PATH="params/demo/tBL_WSe2_reconstruct.yml"
echo params_path = ${PARAMS_PATH}

nvidia-smi

# accelerate env
# accelerate test
# Run the above line to check the accelerate configuration

# python -u ./scripts/run_ptyrad.py --params_path "${PARAMS_PATH}" 2>&1 # This runs typical python on 1 GPU
accelerate launch --multi_gpu --num_processes=2 ./scripts/run_ptyrad.py --params_path "${PARAMS_PATH}" 2>&1 # This runs DDP on 2 GPUs via `accelerate`

date